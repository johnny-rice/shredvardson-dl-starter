=== DELEGATION PACKAGE FOR ISSUE #243 ===

Please implement this following our project standards.

## Issue Details

**#243**: Add AI usage annotation to PR template

## Problem

The current PR template lacks transparency about AI-generated code, making it difficult for reviewers to:
- Know which code requires extra scrutiny
- Understand the extent of AI assistance used
- Apply appropriate review rigor based on AI involvement
- Track AI usage patterns across the team

**Source:** AI-Augmented SDLC research recommendations (GPT-5 prompt review)

## Impact

- **P1 (High)**: Critical for AI-assisted development transparency
- Reviewers can't adjust their approach based on AI involvement
- Missing data for measuring AI effectiveness
- Risk of lower scrutiny on AI-generated code that needs more review

## Current State

- ‚úÖ Comprehensive PR template with quality checks
- ‚úÖ AI Review Status section (but advisory only)
- ‚ùå No field indicating % of AI-generated code
- ‚ùå No tracking of which parts used AI assistance
- ‚ùå No guidance on what constitutes "AI assistance"

## Solution

Add explicit AI usage annotation field to PR template.

### Proposed Addition

Update [.github/pull_request_template.md](.github/pull_request_template.md):

```markdown
## AI Assistance Disclosure

**AI Assistance Used:** ‚òê None / ‚òê Minimal (<25%) / ‚òê Moderate (25-75%) / ‚òê Significant (>75%)

**AI-Generated Components:** _(List specific files/functions that were primarily AI-generated)_
- 

**AI Tools Used:** _(e.g., Claude Code, GitHub Copilot, Cursor, etc.)_
- 

**Human Review Applied:**
- [ ] All AI-generated code reviewed line-by-line
- [ ] Edge cases manually tested
- [ ] Security implications considered
- [ ] Performance implications validated

**Notes:** _(Optional: Describe AI workflow, prompt strategies, or lessons learned)_
```

### Alternative: Simple Percentage Field

Minimal version:

```markdown
## AI Assistance

**Estimated AI contribution:** ____%

_List components with significant AI generation:_
- 

_All AI-generated code has been reviewed and tested manually: ‚òê Yes_
```

## Acceptance Criteria

- [ ] PR template updated with AI usage field
- [ ] Guidance added on what counts as "AI assistance"
- [ ] Example PR created demonstrating proper disclosure
- [ ] Team notified of new requirement
- [ ] CONTRIBUTING.md updated with AI disclosure expectations
- [ ] Decision documented (full version vs minimal version)

## Benefits

1. **Transparency**: Reviewers know what to scrutinize
2. **Context**: Understanding AI involvement helps with review approach
3. **Metrics**: Track AI effectiveness and patterns over time
4. **Quality**: Encourages proper human review of AI code
5. **Learning**: Share successful AI workflows through notes
6. **Compliance**: Demonstrates responsible AI usage practices

## Guidance on "AI Assistance"

Create `docs/ai/AI_DISCLOSURE_GUIDE.md`:

**Counts as AI Assistance:**
- Code generated by AI tools (Claude, Copilot, etc.)
- Significant refactoring suggested by AI
- Architecture/design decisions guided by AI
- Test generation via AI tools

**Does NOT count:**
- Autocomplete/IntelliSense
- Simple code formatting
- Grammar/spell-check in comments
- Documentation typo fixes

**Estimation Guidelines:**
- **None (0%)**: Wrote everything manually
- **Minimal (<25%)**: AI helped with boilerplate or suggestions
- **Moderate (25-75%)**: AI generated structure, human refined
- **Significant (>75%)**: Primarily AI-generated, human reviewed

## Integration with Existing Checks

Update PR template checklist:

```markdown
## Verification

- [ ] `pnpm run doctor:report` (attach artifacts/doctor-report.md)
- [ ] AI assistance disclosed (if applicable)
- [ ] All AI-generated code reviewed manually
...
```

## References

- [AI-Augmented SDLC: PR Template Recommendations](https://github.com/anthropics/ai-augmented-sdlc)
- [Responsible AI Development Practices](https://www.anthropic.com/responsible-ai)
- Current PR template: [.github/pull_request_template.md](.github/pull_request_template.md)

---

**Priority:** P1 (High) - Critical for responsible AI development
**Effort:** Small (1-2 hours)
**Lane:** Simple

---

## Spec

---
title: Add AI usage annotation to PR template
type: docs
priority: p1
status: draft
lane: simple
issue: 243
created: 2025-11-07
---

# Add AI usage annotation to PR template

## Summary

Add explicit AI usage disclosure field to the PR template to provide transparency about AI-generated code, enabling reviewers to apply appropriate scrutiny and track AI effectiveness across the team.

## Problem Statement

The current PR template lacks transparency about AI-generated code, making it difficult for reviewers to:
- Know which code requires extra scrutiny
- Understand the extent of AI assistance used
- Apply appropriate review rigor based on AI involvement
- Track AI usage patterns across the team

While we have an "AI Review Status" section, it's advisory only and doesn't capture:
- Percentage of AI-generated code
- Which specific components used AI assistance
- What constitutes "AI assistance" (unclear definition)

**Impact:** P1 (High) - Critical for AI-assisted development transparency and responsible AI usage practices.

## Proposed Solution

Add a new "AI Assistance Disclosure" section to `.github/pull_request_template.md` with structured fields for:
1. **AI contribution percentage** (None/Minimal/Moderate/Significant)
2. **AI-generated components** (specific files/functions)
3. **AI tools used** (Claude Code, Copilot, etc.)
4. **Human review checklist** (line-by-line review, testing, security validation)
5. **Optional notes** (workflow lessons, prompt strategies)

**Two proposed formats:**

### Full Version (Recommended):
```markdown
## AI Assistance Disclosure

**AI Assistance Used:** ‚òê None / ‚òê Minimal (<25%) / ‚òê Moderate (25-75%) / ‚òê Significant (>75%)

**AI-Generated Components:** _(List specific files/functions that were primarily AI-generated)_
-

**AI Tools Used:** _(e.g., Claude Code, GitHub Copilot, Cursor, etc.)_
-

**Human Review Applied:**
- [ ] All AI-generated code reviewed line-by-line
- [ ] Edge cases manually tested
- [ ] Security implications considered
- [ ] Performance implications validated

**Notes:** _(Optional: Describe AI workflow, prompt strategies, or lessons learned)_
```

### Minimal Version:
```markdown
## AI Assistance

**Estimated AI contribution:** ____%

_List components with significant AI generation:_
-

_All AI-generated code has been reviewed and tested manually: ‚òê Yes_
```

**Decision:** Full version recommended for comprehensive tracking and learning.

## Acceptance Criteria

- [ ] `.github/pull_request_template.md` updated with AI Assistance Disclosure section
- [ ] Section placed after "AI Review Status" section (logical grouping)
- [ ] Guidance document created: `docs/ai/AI_DISCLOSURE_GUIDE.md` defining:
  - What counts as "AI assistance" vs what doesn't
  - Estimation guidelines (None/Minimal/Moderate/Significant)
  - Examples of proper disclosure
- [ ] `CONTRIBUTING.md` updated to reference AI disclosure as required step
- [ ] Example PR created demonstrating proper disclosure
- [ ] Team notified of new requirement via GitHub discussion or Slack
- [ ] PR template passes markdown linting (pnpm lint)
- [ ] Documentation follows project markdown standards (code blocks with language identifiers)

## Technical Constraints

- Must integrate with existing PR template structure and checklist format
- Must align with existing AI disclosure footer pattern: "ü§ñ Generated with [Claude Code](https://claude.com/claude-code)"
- Should not significantly increase PR creation time (keep concise)
- Must be compatible with PR autofill GitHub Action (`.github/workflows/pr-autofill.yml`)
- Should support future automation (e.g., metrics collection from AI disclosure data)

## Success Metrics

- 100% of PRs include AI disclosure section (measured via PR template compliance)
- Reviewers report increased confidence in review approach based on AI disclosure
- Zero incidents of AI-generated code being rubber-stamped without proper review
- Team shares AI workflow learnings through optional notes field
- Metrics available for tracking AI effectiveness over time

## Out of Scope

- Automated detection of AI-generated code (future tooling)
- AI usage analytics dashboard (separate feature)
- Integration with AI tool APIs for automatic disclosure (vendor-specific)
- Enforcement mechanisms beyond manual checklist (future automation)
- Comprehensive AI ethics guidelines (separate documentation)

## References

**Similar Implementations Found:**
- [.github/pull_request_template.md](.github/pull_request_template.md) - Current PR template with checkbox structure
- [.claude/agents/pr-template-agent.md](.claude/agents/pr-template-agent.md) - PR automation agent with structured JSON output
- [.claude/prompts/pr-template-agent.md](.claude/prompts/pr-template-agent.md) - PR template filling automation
- [CONTRIBUTING.md](CONTRIBUTING.md) - Contributing guidelines with quality standards
- [docs/llm/CONTRIBUTING_LLMS.md](docs/llm/CONTRIBUTING_LLMS.md) - AI-specific contributing guidelines
- [docs/constitution.md](docs/constitution.md) - Governance and architectural principles

**AI Disclosure Pattern (20+ files):**
- Footer format: "ü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>"
- Used in prompts, agents, documentation, ADRs, and commit messages
- Part of git workflow command standards

**Architecture Patterns:**
- YAML frontmatter for structured metadata
- Checkbox-based checklists for verification
- Traceability linking (Issue ‚Üí Spec ‚Üí Plan ‚Üí Task ‚Üí PR)
- Progressive disclosure (minimal primary, detailed subdirectories)
- Machine-readable + human-readable dual documentation

**Related Issues:**
- Issue #250 (SECURE_PROMPTING.md) - Defines secure AI usage practices
- AI-Augmented SDLC research recommendations
- Part of responsible AI development transparency initiative

**External Standards:**
- AI-Augmented SDLC: PR Template Recommendations
- Anthropic Responsible AI Development Practices
- GPT-5 prompt review recommendations

## AI Disclosure Guidance (Draft)

**Counts as AI Assistance:**
- Code generated by AI tools (Claude, Copilot, etc.)
- Significant refactoring suggested by AI
- Architecture/design decisions guided by AI
- Test generation via AI tools

**Does NOT count:**
- Autocomplete/IntelliSense
- Simple code formatting
- Grammar/spell-check in comments
- Documentation typo fixes

**Estimation Guidelines:**
- **None (0%)**: Wrote everything manually
- **Minimal (<25%)**: AI helped with boilerplate or suggestions
- **Moderate (25-75%)**: AI generated structure, human refined
- **Significant (>75%)**: Primarily AI-generated, human reviewed

---

## Implementation Requirements

### Git Setup

The spec file is located on branch: `specs/batch-2025-11-07-1502`

To retrieve the spec before starting work:

```bash
# Fetch the latest changes
git fetch origin specs/batch-2025-11-07-1502

# Create your feature branch from main/master
git switch -c feature/243-brief-description

# Copy the spec file from the spec branch
git checkout origin/specs/batch-2025-11-07-1502 -- specs/243-ai-usage-annotation-pr-template.md

# Commit the spec to your feature branch
git commit -m "docs: add spec for issue #243"
```

### Implementation Steps

1. Follow acceptance criteria from spec above
2. Use conventional commit format: `fix:` or `feat:`
3. Run these before pushing:
   - `pnpm typecheck`
   - `pnpm lint`
   - `pnpm test`
4. Reference Spec ID: SPEC-243

---

## PR Template

# Pull Request

> **‚ö†Ô∏è Direct Push Protection Notice**  
> Direct pushes to `main` are blocked. If you see the 'Block Direct Main Pushes' workflow fail, you attempted a direct push‚Äîcreate or continue a PR instead.

## Summary

_What changed and why in 1‚Äì3 sentences._

## Traceability

- **GitHub Issue:** #\_\_\_ (required for spec-driven PRs)
- **Spec ID:** `SPEC-YYYYMMDD-feature-name` (if applicable)
- **Plan ID:** `PLAN-YYYYMMDD-feature-name` (if applicable)
- **Task ID:** `TASK-YYYYMMDD-feature-name` (if applicable)

### ADR (Required for Infrastructure Changes)

ADR: ADR-### | N/A

_**‚ö†Ô∏è REQUIRED for changes to:**_

- _`prompts/**` (AI behavior/prompt engineering)_
- _`scripts/**` (build/deploy scripts)_
- _`.github/workflows/**` (CI/CD workflows)_
- _`docs/wiki/**` (public docs)_

_**Quick create:** `pnpm adr:create "Your Title"` ‚Üí edit file ‚Üí add `ADR: ADR-XXX` above | **Emergency:** use `override:adr` label_

## Scope

- [ ] Single task type (feature/refactor/test/docs)
- [ ] Only touched files listed in docs/llm/context-map.json

## AI Review Status

- [ ] **AI Review:** ‚ö†Ô∏è Not requested / ‚úÖ Requested (`@claude /review`)
- [ ] **Security Scan:** ‚ö†Ô∏è Not applicable / ‚úÖ Completed automatically

_If AI review completed, paste advisory feedback summary from doctor report below:_

```
[Paste "ü§ñ AI Review (Advisory)" or "üõ°Ô∏è AI Security Review (Advisory)" sections from artifacts/doctor-report.md]
```

## Verification

Paste real outputs or "OK":

- [ ] `pnpm run doctor:report` (attach artifacts/doctor-report.md)
- [ ] `pnpm -w turbo run lint`
- [ ] `pnpm -w turbo run typecheck`
- [ ] `pnpm -w turbo run build`
- [ ] `pnpm -w turbo run test:e2e` (or N/A)
- [ ] `pnpm audit:traceability` (if using specs/plans/tasks)
- [ ] `pnpm tsx scripts/docs-check.ts` (docs-link-check)
- [ ] `pnpm learn:index` (if micro-lessons changed)

_üí° **Tip**: If doctor checks fail due to timing issues, comment `/doctor recheck` to manually re-run (maintainers/write access only)._

## Doctor & Quality Checks

- [ ] I ran `pnpm doctor` locally (no fails)
- [ ] All referenced scripts/paths in my changed docs exist
- [ ] New `.claude/commands/*` files are linked in `docs/ai/CLAUDE.md`
- [ ] If I intentionally left placeholders, I added them to `.doctor-allowlist.json` (with comment why)
- [ ] Prompt files have required headers (Intent, Inputs, Expected Output, Risks/Guardrails)
- [ ] Doc files have H1, summary, and "When to use" sections
- [ ] No tracked files in artifacts/ directory

## Learning Loop

- [ ] **Learning reference:** Checked docs/micro-lessons/INDEX.md for relevant patterns
- [ ] **Pattern application:** Applied relevant micro-lessons to avoid known issues
- [ ] **New learning:** Created/updated micro-lesson if new pattern emerged
- [ ] **Saved rework:** Micro-lesson prevented significant debugging/refactoring time

Common patterns to check (as applicable):

- [ ] Isolation hooks checked (no hidden state coupling)
- [ ] Mock at the **boundary** (env/config or network), not deep internals
- [ ] Stable React keys (no array indices)
- [ ] Dead code removed (no unreachable branches after early returns)
- [ ] Async assertions use Testing Library's `waitFor*` (no flake‚Äëprone timeouts)
- [ ] Memoize expensive values/objects in render paths

Refs:

- Top‚Äë10 Index: docs/micro-lessons/INDEX.md
- Template: docs/micro-lessons/template.md

## LLM Guardrails

- [ ] Used adapters (no vendor SDKs in UI)
- [ ] No hardcoded hex colors (tokenized Tailwind only)
- [ ] Updated docs and `llm/context-map.json` if scripts/paths changed

## Used Micro-Lesson

_Optional: reference any micro-lesson that helped avoid an issue (e.g., test-isolation-hooks)_

## Breaking changes / Migration

_None_ (or describe + steps)
